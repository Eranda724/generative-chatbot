{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f1fb7b-02ae-420b-8d7d-f0b5dd3299bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load and Preprocess Data\n",
    "filename = \"mental_H.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    raw_text = file.read().lower()\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "sequences = tokenizer.texts_to_sequences([raw_text])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "seq_length = 100\n",
    "\n",
    "# Create Input-Output Pairs\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(sequences) - seq_length):\n",
    "    X.append(sequences[i:i + seq_length])\n",
    "    y.append(sequences[i + seq_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# Reshape for LSTM Input\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1]))\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 256, input_length=seq_length),\n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(256)),\n",
    "    Dropout(0.3),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model Summary\n",
    "\n",
    "\n",
    "# Checkpointing\n",
    "\n",
    "\n",
    "# Load Best Weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a27254-b1a5-4f8d-9028-b566fafcc222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 256)          18688     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100, 512)         1050624   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 512)          0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100, 512)         2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 512)              1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 73)                37449     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,683,721\n",
      "Trainable params: 2,682,697\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75f473-e0a1-4d62-aae4-b8f3779a7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4617/4659 [============================>.] - ETA: 5s - loss: 1.8441 - accuracy: 0.4655"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-best.hdf5\", monitor=\"loss\", save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a489371-24fe-44a5-821f-0588970bbd6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign value to variable ' embedding/embeddings:0': Shape mismatch.The variable shape (73, 256), and the assigned value shape (5057, 256) are incompatible.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweights-best1.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Generate Text\u001b[39;00m\n\u001b[0;32m      4\u001b[0m seed_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\backend.py:4302\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m tf\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m   4301\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, value \u001b[38;5;129;01min\u001b[39;00m tuples:\n\u001b[1;32m-> 4302\u001b[0m         \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_graph()\u001b[38;5;241m.\u001b[39mas_default():\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot assign value to variable ' embedding/embeddings:0': Shape mismatch.The variable shape (73, 256), and the assigned value shape (5057, 256) are incompatible."
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights-best1.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "for _ in range(1000):  # Generate 1000 characters\n",
    "    pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "    pred_probs = model.predict(pred_input, verbose=0)\n",
    "    next_idx = np.argmax(pred_probs)\n",
    "    output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "    seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\"\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698fb40-c3c9-4aab-b328-760df270b392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7998b-e40f-4e89-a4b6-b13c19bce245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "temperature = 1.0  # Lower values make text more deterministic; higher values make it more diverse.\n",
    "\n",
    "for i in range(2000):  # Generate 1000 characters\n",
    "    if i<1500:\n",
    "        pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "        pred_probs = model.predict(pred_input, verbose=0)\n",
    "        next_idx = np.argmax(pred_probs)\n",
    "        output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "        seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "        \n",
    "    else:\n",
    "        if seed_idx == \".\":\n",
    "            break\n",
    "        else:\n",
    "            pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "            pred_probs = model.predict(pred_input, verbose=0)\n",
    "            next_idx = np.argmax(pred_probs)\n",
    "            output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "            # Update seed sequence\n",
    "            seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "            \n",
    "        \n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\"\".join(output)+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d30ed-4b77-46c1-890f-550c1c372995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b1335-e72f-4540-a42a-f0fa59a49d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
