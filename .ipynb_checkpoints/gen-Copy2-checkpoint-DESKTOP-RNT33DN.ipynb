{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5f1fb7b-02ae-420b-8d7d-f0b5dd3299bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load and Preprocess Data\n",
    "filename = \"wizard_of_us.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    raw_text = file.read().lower()\n",
    "import re\n",
    "\n",
    "# Remove unnecessary characters and normalize text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.strip().lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "raw_text = clean_text(raw_text)\n",
    "\n",
    "# Tokenization\n",
    "##\n",
    "tokenizer = Tokenizer(num_words=5000)  # Limit vocab size to 5000\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "##\n",
    "sequences = tokenizer.texts_to_sequences([raw_text])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "##\n",
    "seq_length = 150\n",
    "\n",
    "# Create Input-Output Pairs\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(sequences) - seq_length):\n",
    "    X.append(sequences[i:i + seq_length])\n",
    "    y.append(sequences[i + seq_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# Reshape for LSTM Input\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1]))\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "X = pad_sequences(X, maxlen=seq_length, padding='pre')\n",
    "\n",
    "# Model Definition\n",
    "##\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 256, input_length=seq_length),\n",
    "    Bidirectional(LSTM(512, return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(512, return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(256)),\n",
    "    Dropout(0.4),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "def lr_scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a27254-b1a5-4f8d-9028-b566fafcc222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 150, 256)          1103616   \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 150, 1024)        3149824   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 150, 1024)         0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 150, 1024)        4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 150, 1024)        6295552   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 150, 1024)         0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 150, 1024)        4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 512)              2623488   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4311)              2211543   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,392,215\n",
      "Trainable params: 15,388,119\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e75f473-e0a1-4d62-aae4-b8f3779a7a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 6.2918 - accuracy: 0.0824\n",
      "Epoch 1: loss improved from inf to 6.29183, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 63s 72ms/step - loss: 6.2918 - accuracy: 0.0824\n",
      "Epoch 2/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 5.8477 - accuracy: 0.1005\n",
      "Epoch 2: loss improved from 6.29183 to 5.84772, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 5.8477 - accuracy: 0.1005\n",
      "Epoch 3/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 5.6139 - accuracy: 0.1182\n",
      "Epoch 3: loss improved from 5.84772 to 5.61391, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 49s 74ms/step - loss: 5.6139 - accuracy: 0.1182\n",
      "Epoch 4/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 5.4175 - accuracy: 0.1275\n",
      "Epoch 4: loss improved from 5.61391 to 5.41750, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 5.4175 - accuracy: 0.1275\n",
      "Epoch 5/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 5.2763 - accuracy: 0.1336\n",
      "Epoch 5: loss improved from 5.41750 to 5.27632, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 5.2763 - accuracy: 0.1336\n",
      "Epoch 6/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 5.0922 - accuracy: 0.1441\n",
      "Epoch 6: loss improved from 5.27632 to 5.09218, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 5.0922 - accuracy: 0.1441\n",
      "Epoch 7/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 4.9311 - accuracy: 0.1498\n",
      "Epoch 7: loss improved from 5.09218 to 4.93106, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 4.9311 - accuracy: 0.1498\n",
      "Epoch 8/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 4.7777 - accuracy: 0.1582\n",
      "Epoch 8: loss improved from 4.93106 to 4.77773, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 4.7777 - accuracy: 0.1582\n",
      "Epoch 9/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 4.6174 - accuracy: 0.1635\n",
      "Epoch 9: loss improved from 4.77773 to 4.61735, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 4.6174 - accuracy: 0.1635\n",
      "Epoch 10/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 4.4630 - accuracy: 0.1734\n",
      "Epoch 10: loss improved from 4.61735 to 4.46305, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 53s 80ms/step - loss: 4.4630 - accuracy: 0.1734\n",
      "Epoch 11/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 4.3057 - accuracy: 0.1824\n",
      "Epoch 11: loss improved from 4.46305 to 4.30567, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 4.3057 - accuracy: 0.1824\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 4.1625 - accuracy: 0.1916\n",
      "Epoch 12: loss improved from 4.30567 to 4.16245, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 4.1625 - accuracy: 0.1916\n",
      "Epoch 13/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 4.0013 - accuracy: 0.2036\n",
      "Epoch 13: loss improved from 4.16245 to 4.00129, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 4.0013 - accuracy: 0.2036\n",
      "Epoch 14/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 3.8655 - accuracy: 0.2119\n",
      "Epoch 14: loss improved from 4.00129 to 3.86551, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 3.8655 - accuracy: 0.2119\n",
      "Epoch 15/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 3.6982 - accuracy: 0.2307\n",
      "Epoch 15: loss improved from 3.86551 to 3.69815, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 3.6982 - accuracy: 0.2307\n",
      "Epoch 16/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 3.5413 - accuracy: 0.2478\n",
      "Epoch 16: loss improved from 3.69815 to 3.54134, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 3.5413 - accuracy: 0.2478\n",
      "Epoch 17/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 3.3918 - accuracy: 0.2679\n",
      "Epoch 17: loss improved from 3.54134 to 3.39181, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 3.3918 - accuracy: 0.2679\n",
      "Epoch 18/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 3.2599 - accuracy: 0.2868\n",
      "Epoch 18: loss improved from 3.39181 to 3.25986, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 3.2599 - accuracy: 0.2868\n",
      "Epoch 19/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 3.1227 - accuracy: 0.3062\n",
      "Epoch 19: loss improved from 3.25986 to 3.12268, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 3.1227 - accuracy: 0.3062\n",
      "Epoch 20/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 3.0231 - accuracy: 0.3248\n",
      "Epoch 20: loss improved from 3.12268 to 3.02312, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 3.0231 - accuracy: 0.3248\n",
      "Epoch 21/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.8789 - accuracy: 0.3511\n",
      "Epoch 21: loss improved from 3.02312 to 2.87895, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 2.8789 - accuracy: 0.3511\n",
      "Epoch 22/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.7600 - accuracy: 0.3666\n",
      "Epoch 22: loss improved from 2.87895 to 2.76000, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 2.7600 - accuracy: 0.3666\n",
      "Epoch 23/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.6483 - accuracy: 0.3873\n",
      "Epoch 23: loss improved from 2.76000 to 2.64833, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 2.6483 - accuracy: 0.3873\n",
      "Epoch 24/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.5472 - accuracy: 0.4052\n",
      "Epoch 24: loss improved from 2.64833 to 2.54725, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 2.5472 - accuracy: 0.4052\n",
      "Epoch 25/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.4565 - accuracy: 0.4221\n",
      "Epoch 25: loss improved from 2.54725 to 2.45650, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 2.4565 - accuracy: 0.4221\n",
      "Epoch 26/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.3730 - accuracy: 0.4362\n",
      "Epoch 26: loss improved from 2.45650 to 2.37304, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 368s 561ms/step - loss: 2.3730 - accuracy: 0.4362\n",
      "Epoch 27/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.2762 - accuracy: 0.4547\n",
      "Epoch 27: loss improved from 2.37304 to 2.27622, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 48s 74ms/step - loss: 2.2762 - accuracy: 0.4547\n",
      "Epoch 28/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.1912 - accuracy: 0.4706\n",
      "Epoch 28: loss improved from 2.27622 to 2.19124, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 2.1912 - accuracy: 0.4706\n",
      "Epoch 29/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.0992 - accuracy: 0.4885\n",
      "Epoch 29: loss improved from 2.19124 to 2.09919, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 2.0992 - accuracy: 0.4885\n",
      "Epoch 30/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 2.0251 - accuracy: 0.5057\n",
      "Epoch 30: loss improved from 2.09919 to 2.02514, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 2.0251 - accuracy: 0.5057\n",
      "Epoch 31/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.9399 - accuracy: 0.5211\n",
      "Epoch 31: loss improved from 2.02514 to 1.93991, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 1.9399 - accuracy: 0.5211\n",
      "Epoch 32/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.8683 - accuracy: 0.5331\n",
      "Epoch 32: loss improved from 1.93991 to 1.86828, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 1.8683 - accuracy: 0.5331\n",
      "Epoch 33/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.8091 - accuracy: 0.5487\n",
      "Epoch 33: loss improved from 1.86828 to 1.80913, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 1.8091 - accuracy: 0.5487\n",
      "Epoch 34/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.7363 - accuracy: 0.5629\n",
      "Epoch 34: loss improved from 1.80913 to 1.73633, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 375s 571ms/step - loss: 1.7363 - accuracy: 0.5629\n",
      "Epoch 35/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.6867 - accuracy: 0.5719\n",
      "Epoch 35: loss improved from 1.73633 to 1.68667, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 48s 73ms/step - loss: 1.6867 - accuracy: 0.5719\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.6170 - accuracy: 0.5892\n",
      "Epoch 36: loss improved from 1.68667 to 1.61703, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 1.6170 - accuracy: 0.5892\n",
      "Epoch 37/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.5470 - accuracy: 0.6051\n",
      "Epoch 37: loss improved from 1.61703 to 1.54698, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 49s 75ms/step - loss: 1.5470 - accuracy: 0.6051\n",
      "Epoch 38/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.4966 - accuracy: 0.6154\n",
      "Epoch 38: loss improved from 1.54698 to 1.49659, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 1.4966 - accuracy: 0.6154\n",
      "Epoch 39/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.4404 - accuracy: 0.6287\n",
      "Epoch 39: loss improved from 1.49659 to 1.44036, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 1.4404 - accuracy: 0.6287\n",
      "Epoch 40/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.3842 - accuracy: 0.6384\n",
      "Epoch 40: loss improved from 1.44036 to 1.38420, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 1.3842 - accuracy: 0.6384\n",
      "Epoch 41/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.3339 - accuracy: 0.6515\n",
      "Epoch 41: loss improved from 1.38420 to 1.33386, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 1.3339 - accuracy: 0.6515\n",
      "Epoch 42/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.2893 - accuracy: 0.6607\n",
      "Epoch 42: loss improved from 1.33386 to 1.28934, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 1.2893 - accuracy: 0.6607\n",
      "Epoch 43/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.2490 - accuracy: 0.6706\n",
      "Epoch 43: loss improved from 1.28934 to 1.24898, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 1.2490 - accuracy: 0.6706\n",
      "Epoch 44/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.2034 - accuracy: 0.6818\n",
      "Epoch 44: loss improved from 1.24898 to 1.20343, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 1.2034 - accuracy: 0.6818\n",
      "Epoch 45/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.1589 - accuracy: 0.6923\n",
      "Epoch 45: loss improved from 1.20343 to 1.15892, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 1.1589 - accuracy: 0.6923\n",
      "Epoch 46/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.1078 - accuracy: 0.7025\n",
      "Epoch 46: loss improved from 1.15892 to 1.10777, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 1.1078 - accuracy: 0.7025\n",
      "Epoch 47/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.0856 - accuracy: 0.7101\n",
      "Epoch 47: loss improved from 1.10777 to 1.08565, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 1.0856 - accuracy: 0.7101\n",
      "Epoch 48/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 1.0444 - accuracy: 0.7184\n",
      "Epoch 48: loss improved from 1.08565 to 1.04439, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 1.0444 - accuracy: 0.7184\n",
      "Epoch 49/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.9972 - accuracy: 0.7303\n",
      "Epoch 49: loss improved from 1.04439 to 0.99716, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.9972 - accuracy: 0.7303\n",
      "Epoch 50/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.9665 - accuracy: 0.7396\n",
      "Epoch 50: loss improved from 0.99716 to 0.96651, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.9665 - accuracy: 0.7396\n",
      "Epoch 51/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.9268 - accuracy: 0.7479\n",
      "Epoch 51: loss improved from 0.96651 to 0.92678, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.9268 - accuracy: 0.7479\n",
      "Epoch 52/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.9015 - accuracy: 0.7529\n",
      "Epoch 52: loss improved from 0.92678 to 0.90149, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.9015 - accuracy: 0.7529\n",
      "Epoch 53/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.8698 - accuracy: 0.7596\n",
      "Epoch 53: loss improved from 0.90149 to 0.86977, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.8698 - accuracy: 0.7596\n",
      "Epoch 54/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.8396 - accuracy: 0.7678\n",
      "Epoch 54: loss improved from 0.86977 to 0.83959, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.8396 - accuracy: 0.7678\n",
      "Epoch 55/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.8074 - accuracy: 0.7771\n",
      "Epoch 55: loss improved from 0.83959 to 0.80741, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.8074 - accuracy: 0.7771\n",
      "Epoch 56/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.7890 - accuracy: 0.7824\n",
      "Epoch 56: loss improved from 0.80741 to 0.78901, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.7890 - accuracy: 0.7824\n",
      "Epoch 57/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.7561 - accuracy: 0.7889\n",
      "Epoch 57: loss improved from 0.78901 to 0.75607, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.7561 - accuracy: 0.7889\n",
      "Epoch 58/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.7948\n",
      "Epoch 58: loss improved from 0.75607 to 0.73042, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.7304 - accuracy: 0.7948\n",
      "Epoch 59/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.7120 - accuracy: 0.8014\n",
      "Epoch 59: loss improved from 0.73042 to 0.71197, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.7120 - accuracy: 0.8014\n",
      "Epoch 60/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.6867 - accuracy: 0.8062\n",
      "Epoch 60: loss improved from 0.71197 to 0.68673, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.6867 - accuracy: 0.8062\n",
      "Epoch 61/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.6673 - accuracy: 0.8117\n",
      "Epoch 61: loss improved from 0.68673 to 0.66725, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.6673 - accuracy: 0.8117\n",
      "Epoch 62/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.8204\n",
      "Epoch 62: loss improved from 0.66725 to 0.63923, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.6392 - accuracy: 0.8204\n",
      "Epoch 63/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.6332 - accuracy: 0.8221\n",
      "Epoch 63: loss improved from 0.63923 to 0.63317, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.6332 - accuracy: 0.8221\n",
      "Epoch 64/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.8263\n",
      "Epoch 64: loss improved from 0.63317 to 0.61252, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 53s 80ms/step - loss: 0.6125 - accuracy: 0.8263\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.8360\n",
      "Epoch 65: loss improved from 0.61252 to 0.58043, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.5804 - accuracy: 0.8360\n",
      "Epoch 66/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.5717 - accuracy: 0.8364\n",
      "Epoch 66: loss improved from 0.58043 to 0.57168, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.5717 - accuracy: 0.8364\n",
      "Epoch 67/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.5627 - accuracy: 0.8397\n",
      "Epoch 67: loss improved from 0.57168 to 0.56265, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 53s 80ms/step - loss: 0.5627 - accuracy: 0.8397\n",
      "Epoch 68/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.5443 - accuracy: 0.8454\n",
      "Epoch 68: loss improved from 0.56265 to 0.54432, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 80ms/step - loss: 0.5443 - accuracy: 0.8454\n",
      "Epoch 69/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.8506\n",
      "Epoch 69: loss improved from 0.54432 to 0.52749, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.5275 - accuracy: 0.8506\n",
      "Epoch 70/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.8510\n",
      "Epoch 70: loss improved from 0.52749 to 0.51526, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.5153 - accuracy: 0.8510\n",
      "Epoch 71/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.8573\n",
      "Epoch 71: loss improved from 0.51526 to 0.49921, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4992 - accuracy: 0.8573\n",
      "Epoch 72/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8600\n",
      "Epoch 72: loss improved from 0.49921 to 0.49200, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4920 - accuracy: 0.8600\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.8665\n",
      "Epoch 73: loss improved from 0.49200 to 0.46719, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4672 - accuracy: 0.8665\n",
      "Epoch 74/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.8673\n",
      "Epoch 74: loss improved from 0.46719 to 0.46368, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 53s 80ms/step - loss: 0.4637 - accuracy: 0.8673\n",
      "Epoch 75/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.8747\n",
      "Epoch 75: loss improved from 0.46368 to 0.44601, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4460 - accuracy: 0.8747\n",
      "Epoch 76/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8705\n",
      "Epoch 76: loss did not improve from 0.44601\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.4471 - accuracy: 0.8705\n",
      "Epoch 77/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8757\n",
      "Epoch 77: loss improved from 0.44601 to 0.43150, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4315 - accuracy: 0.8757\n",
      "Epoch 78/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.8787\n",
      "Epoch 78: loss improved from 0.43150 to 0.42277, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4228 - accuracy: 0.8787\n",
      "Epoch 79/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4106 - accuracy: 0.8821\n",
      "Epoch 79: loss improved from 0.42277 to 0.41057, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.4106 - accuracy: 0.8821\n",
      "Epoch 80/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8832\n",
      "Epoch 80: loss improved from 0.41057 to 0.40253, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.4025 - accuracy: 0.8832\n",
      "Epoch 81/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.8842\n",
      "Epoch 81: loss improved from 0.40253 to 0.39889, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 76ms/step - loss: 0.3989 - accuracy: 0.8842\n",
      "Epoch 82/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.8866\n",
      "Epoch 82: loss improved from 0.39889 to 0.39167, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 52s 79ms/step - loss: 0.3917 - accuracy: 0.8866\n",
      "Epoch 83/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3730 - accuracy: 0.8916\n",
      "Epoch 83: loss improved from 0.39167 to 0.37304, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3730 - accuracy: 0.8916\n",
      "Epoch 84/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.8923\n",
      "Epoch 84: loss improved from 0.37304 to 0.36850, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3685 - accuracy: 0.8923\n",
      "Epoch 85/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.8928\n",
      "Epoch 85: loss did not improve from 0.36850\n",
      "657/657 [==============================] - 52s 78ms/step - loss: 0.3688 - accuracy: 0.8928\n",
      "Epoch 86/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8937\n",
      "Epoch 86: loss improved from 0.36850 to 0.36229, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3623 - accuracy: 0.8937\n",
      "Epoch 87/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8979\n",
      "Epoch 87: loss improved from 0.36229 to 0.35396, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.3540 - accuracy: 0.8979\n",
      "Epoch 88/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.8995\n",
      "Epoch 88: loss improved from 0.35396 to 0.34201, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3420 - accuracy: 0.8995\n",
      "Epoch 89/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3357 - accuracy: 0.9022\n",
      "Epoch 89: loss improved from 0.34201 to 0.33571, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3357 - accuracy: 0.9022\n",
      "Epoch 90/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.9019\n",
      "Epoch 90: loss improved from 0.33571 to 0.33545, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3354 - accuracy: 0.9019\n",
      "Epoch 91/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.9034\n",
      "Epoch 91: loss improved from 0.33545 to 0.32700, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.3270 - accuracy: 0.9034\n",
      "Epoch 92/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.9049\n",
      "Epoch 92: loss did not improve from 0.32700\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3271 - accuracy: 0.9049\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3236 - accuracy: 0.9051\n",
      "Epoch 93: loss improved from 0.32700 to 0.32359, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 78ms/step - loss: 0.3236 - accuracy: 0.9051\n",
      "Epoch 94/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.9060\n",
      "Epoch 94: loss improved from 0.32359 to 0.32023, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3202 - accuracy: 0.9060\n",
      "Epoch 95/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.9113\n",
      "Epoch 95: loss improved from 0.32023 to 0.30559, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.3056 - accuracy: 0.9113\n",
      "Epoch 96/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.3041 - accuracy: 0.9096\n",
      "Epoch 96: loss improved from 0.30559 to 0.30409, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.3041 - accuracy: 0.9096\n",
      "Epoch 97/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.9147\n",
      "Epoch 97: loss improved from 0.30409 to 0.29116, saving model to weights-best2.hdf5\n",
      "657/657 [==============================] - 51s 77ms/step - loss: 0.2912 - accuracy: 0.9147\n",
      "Epoch 98/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.9134\n",
      "Epoch 98: loss did not improve from 0.29116\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.2949 - accuracy: 0.9134\n",
      "Epoch 99/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.9122\n",
      "Epoch 99: loss did not improve from 0.29116\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.2946 - accuracy: 0.9122\n",
      "Epoch 100/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.2924 - accuracy: 0.9146\n",
      "Epoch 100: loss did not improve from 0.29116\n",
      "657/657 [==============================] - 50s 77ms/step - loss: 0.2924 - accuracy: 0.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27d429dfee0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-best2.hdf5\", monitor=\"loss\", save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", patience=5, restore_best_weights=True)\n",
    "callbacks = [checkpoint, early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a489371-24fe-44a5-821f-0588970bbd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "eat have no personal experience in such matters but i remember that our great poet once said to eat is sweet when hungers seat demands a treat of savory meat take this into consideration friends of the jury and you will readily decide that the kitten is wrongfully accused and should be set at liberty when the tin woodman sat down no one applauded him for his arguments had not been very convincing and few believed that he had proved eurekas innocence as for the jury the members whispered to each other for a few minutes and then they appointed the hungry tiger their spokesman the huge beast slowly arose and said kittens have no consciences so they eat whatever pleases them the jury believes the white kitten known as eureka is guilty of having eaten the piglet owned by princess ozma and recommends that she be put to death in punishment of the crime the judgment of the jury was received with great applause although dorothy was sobbing miserably at the fate of her pet the princess was just about to order eurekas head chopped off with the tin woodmans axe when that brilliant personage once more arose and addressed her your highness said he see how easy it is for a jury to be mistaken the kitten could not have eaten your pigletfor here it is he took off his funnel hat and from beneath it produced a tiny white piglet which he held aloft that all might see it clearly ozma was delighted and exclaimed eagerly give me my pet nick chopper and all the people cheered and clapped their hands rejoicing that the prisoner had escaped death and been proved to be innocent as the princess held the white piglet in her arms and stroked its soft hair she said let eureka out of the cage for she is no longer a prisoner but our good friend where did you find my missing pet nick chopper in a room of the palace he answered justice remarked the scarecrow with a sigh is a dangerous thing to meddle with if you hadnt happened to find the piglet eureka would surely have been executed but justice prevailed at the last said ozma for here is my pet and eureka is once more free i refuse to be free cried the kitten in a sharp voice unless the wizard can do his trick with eight piglets if he can produce but seven then this it not the piglet that was lost but another one hush eureka warned the wizard dont be foolish advised the tin woodman or you may be sorry for it the piglet that belonged to the princess wore an emerald collar said eureka loudly enough for all to hear so it did exclaimed ozma this cannot be the one the wizard gave me of course not he had nine of them altogether declared eureka and i must say it was very stingy of him not to let me eat just a few but now that this foolish trial is ended i will tell you what really became of your pet piglet at this everyone in the throne room suddenly became quiet and the kitten continued in a calm mocking tone of voice i will confess that i intended to eat the little pig for my breakfast so i crept into the room where it was kept while the princess was dressing and hid myself under a chair when ozma went away she closed the door and left her pet on the table at once i jumped up and told the piglet not to make a fuss for he would be inside of me in half a second but no one can teach one of these creatures to be reasonable instead of keeping still so i could eat him comfortably he trembled so with fear that he fell off the table into a big vase that was standing on the floor the vase had a very small neck and spread out at the top like a bowl at first the piglet stuck in the neck of the vase and i thought i should get him after all but he wriggled himself through and fell down into the deep bottom partand i suppose hes there yet all were astonished at this confession and ozma at once sent an officer to her room to fetch the vase when he returned the princess looked down the narrow neck of the big ornament and discovered her lost piglet just as eureka had said she would there was no way to get the creature out without breaking the vase so the tin woodman smashed it with his axe and set the little prisoner free then the crowd cheered lustily and dorothy hugged the kitten in her arms and told her how delighted she was to know that she was innocent but why didnt you tell us at first she asked it would have spoiled the fun replied the kitten yawning ozma gave the wizard back the piglet he had so kindly allowed nick chopper to substitute for the lost one and then she carried her own into the apartments of the palace where she lived and now the trial being over the good citizens of the emerald city scattered to their homes well content with the days amusement chapter 20 zeb returns to the ranch eureka was much surprised to find herself in disgrace but she was in spite of the fact that she had not eaten the piglet for the folks of oz knew the kitten had tried to commit the crime and that only an accident had prevented her from doing so therefore even the hungry tiger preferred not to associate with her eureka was forbidden to wander around the palace and was made to stay in confinement in dorothys room so she began to beg her mistress to send her to some other place where she could enjoy herself\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights-best2.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "for _ in range(1000):  # Generate 1000 characters\n",
    "    pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "    pred_probs = model.predict(pred_input, verbose=0)\n",
    "    next_idx = np.argmax(pred_probs)\n",
    "    output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "    seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\" \".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0698fb40-c3c9-4aab-b328-760df270b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is some information related to your query:\n",
      "I don't have specific information about that. Let's explore general advice.\n",
      "\n",
      "Chatbot: and worry in the same risk of mental health conditions are not not have a mental health condition is not not have a mental health condition is not not have a mental illness is not not not have a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person has a person\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the trained model\n",
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Define the knowledge base\n",
    "with open('mental_h.txt', 'r', encoding='utf-8') as file:\n",
    "    knowledge_base = file.read()\n",
    "\n",
    "# Extract knowledge base sections\n",
    "def find_relevant_info(user_input, knowledge_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([knowledge_text, user_input])\n",
    "    similarity = vectorizer.toarray().dot(vectorizer.toarray().T)[0, 1]\n",
    "    if similarity > 0.1:\n",
    "        # Extract sentences with relevance\n",
    "        return '\\n'.join([sentence for sentence in knowledge_text.splitlines() if user_input.lower() in sentence.lower()])\n",
    "    return \"I don't have specific information about that. Let's explore general advice.\"\n",
    "\n",
    "# Generate a creative response\n",
    "def generate_response(user_input, tokenizer, model, max_sequence_length, output_length=100):\n",
    "    input_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=max_sequence_length, padding='pre')\n",
    "\n",
    "    output = []\n",
    "    for _ in range(output_length):\n",
    "        pred_probs = model.predict(input_sequence, verbose=0)\n",
    "        next_idx = np.argmax(pred_probs)\n",
    "        output.append(tokenizer.index_word.get(next_idx, \"\"))\n",
    "\n",
    "        input_sequence = np.append(input_sequence[0][1:], next_idx).reshape(1, max_sequence_length)\n",
    "\n",
    "    return \" \".join(output)\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"You: \")\n",
    "relevant_info = find_relevant_info(user_input, knowledge_base)\n",
    "creative_response = generate_response(user_input, tokenizer, model, max_sequence_length=100, output_length=100)\n",
    "\n",
    "response = f\"Here is some information related to your query:\\n{relevant_info}\\n\\nChatbot: {creative_response}\"\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc7998b-e40f-4e89-a4b6-b13c19bce245",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     pred_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(seed_sequence, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(seed_sequence)))\n\u001b[1;32m---> 25\u001b[0m     pred_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     next_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(pred_probs)\n\u001b[0;32m     27\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(tokenizer\u001b[38;5;241m.\u001b[39mindex_word[next_idx])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\engine\\training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2212\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2217\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2218\u001b[0m         )\n\u001b[1;32m-> 2220\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\engine\\data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\engine\\data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1261\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1277\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\engine\\data_adapter.py:347\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m         flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 347\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2245\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   2214\u001b[0m \n\u001b[0;32m   2215\u001b[0m \u001b[38;5;124;03m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2245\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5484\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5482\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5483\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[1;32m-> 5484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5487\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   5488\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5489\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[38;5;66;03m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m placeholder_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39m_capture_func_lib  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[38;5;66;03m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2671\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2672\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2675\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2678\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\keras\\engine\\data_adapter.py:340\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_batch_size:\n\u001b[0;32m    335\u001b[0m     index_remainder \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensors(\n\u001b[0;32m    336\u001b[0m         tf\u001b[38;5;241m.\u001b[39mslice(\n\u001b[0;32m    337\u001b[0m             indices, [num_in_full_batch], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_batch_size]\n\u001b[0;32m    338\u001b[0m         )\n\u001b[0;32m    339\u001b[0m     )\n\u001b[1;32m--> 340\u001b[0m     flat_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mflat_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_remainder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;66;03m# 1024 is a magic constant that has not been properly evaluated\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1294\u001b[0m, in \u001b[0;36mDatasetV2.concatenate\u001b[1;34m(self, dataset, name)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a `Dataset` by concatenating the given dataset with this dataset.\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m \n\u001b[0;32m   1269\u001b[0m \u001b[38;5;124;03m  >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1294\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConcatenateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4894\u001b[0m, in \u001b[0;36mConcatenateDataset.__init__\u001b[1;34m(self, input_dataset, dataset_to_concatenate, name)\u001b[0m\n\u001b[0;32m   4892\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   4893\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 4894\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mconcatenate_dataset(\n\u001b[0;32m   4895\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor, dataset_to_concatenate\u001b[38;5;241m.\u001b[39m_variant_tensor,\n\u001b[0;32m   4896\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m   4897\u001b[0m \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m   4898\u001b[0m \u001b[38;5;28msuper\u001b[39m(ConcatenateDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(variant_tensor)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:1102\u001b[0m, in \u001b[0;36mconcatenate_dataset\u001b[1;34m(input_dataset, another_dataset, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   1100\u001b[0m   metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1101\u001b[0m metadata \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_str(metadata, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1102\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConcatenateDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[43m                            \u001b[49m\u001b[43manother_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manother_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1108\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m arg, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(op_def\u001b[38;5;241m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[38;5;66;03m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_type_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_protos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39moutputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[38;5;241m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFuncGraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_op_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[38;5;66;03m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;66;03m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3801\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3802\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3804\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3805\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontrol_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrol_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3807\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_op\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_original_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[43m      \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3809\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_op_helper(ret, compute_device\u001b[38;5;241m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[38;5;241m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;66;03m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_def\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_input_ops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_c_op(c_op\u001b[38;5;241m=\u001b[39mc_op, g\u001b[38;5;241m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_op \u001b[38;5;241m=\u001b[39m original_op\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_1\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1962\u001b[0m   pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[38;5;241m.\u001b[39mas_str(name),\n\u001b[0;32m   1963\u001b[0m                                          serialized)\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_FinishOperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_desc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "temperature = 1.0  # Lower values make text more deterministic; higher values make it more diverse.\n",
    "\n",
    "for i in range(2000):  # Generate 1000 characters\n",
    "    if i<1500:\n",
    "        pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "        pred_probs = model.predict(pred_input, verbose=0)\n",
    "        next_idx = np.argmax(pred_probs)\n",
    "        output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "        seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "        \n",
    "    else:\n",
    "        if seed_idx == \".\":\n",
    "            break\n",
    "        else:\n",
    "            pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "            pred_probs = model.predict(pred_input, verbose=0)\n",
    "            next_idx = np.argmax(pred_probs)\n",
    "            output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "            # Update seed sequence\n",
    "            seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "            \n",
    "        \n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\"\".join(output)+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d30ed-4b77-46c1-890f-550c1c372995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "test_env_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
