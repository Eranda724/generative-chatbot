{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8bc2db-56cc-4878-a67d-752101a06b18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 56\u001b[0m\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     43\u001b[0m     Embedding(vocab_size, \u001b[38;5;241m256\u001b[39m, input_length\u001b[38;5;241m=\u001b[39mseq_length),\n\u001b[0;32m     44\u001b[0m     Bidirectional(LSTM(\u001b[38;5;241m512\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m     Dense(vocab_size, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m ])\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mAdam\u001b[49m(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "# Load and preprocess data\n",
    "filename = \"wizard_of_us.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    raw_text = file.read().lower()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.strip().lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "raw_text = clean_text(raw_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=10000)  # Increase vocab size\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "sequences = tokenizer.texts_to_sequences([raw_text])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "seq_length = 150\n",
    "\n",
    "# Create input-output pairs\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(sequences) - seq_length):\n",
    "    X.append(sequences[i:i + seq_length])\n",
    "    y.append(sequences[i + seq_length])\n",
    "\n",
    "X = pad_sequences(X, maxlen=seq_length, padding='pre')\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# Model definition\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 256, input_length=seq_length),\n",
    "    Bidirectional(LSTM(512, return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(512, return_sequences=True)),\n",
    "    Dropout(0.4),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(256)),\n",
    "    Dropout(0.4),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68056537-04b7-419a-92be-c3d67622e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-best2.hdf5\", monitor=\"loss\", save_best_only=True, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", patience=5, restore_best_weights=True)\n",
    "callbacks = [checkpoint, early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809327f0-5bce-48b1-a4e6-8807795f0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "def generate_text(seed_sequence, length=1000, temperature=0.7):\n",
    "    output = []\n",
    "    for _ in range(length):\n",
    "        pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "        pred_probs = model.predict(pred_input, verbose=0)[0]\n",
    "        next_idx = sample_with_temperature(pred_probs, temperature)\n",
    "        output.append(tokenizer.index_word[next_idx])\n",
    "        seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "    return \" \".join(output)\n",
    "\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "print(\"Generated Text:\")\n",
    "print(generate_text(seed_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c0c99-9530-4bfc-9b18-ff1351b31ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "test_env_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
