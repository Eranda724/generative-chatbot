{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f1fb7b-02ae-420b-8d7d-f0b5dd3299bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load and Preprocess Data\n",
    "filename = \"mental_H.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    raw_text = file.read().lower()\n",
    "import re\n",
    "\n",
    "# Remove unnecessary characters and normalize text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.strip().lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "raw_text = clean_text(raw_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "sequences = tokenizer.texts_to_sequences([raw_text])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "seq_length = 100\n",
    "\n",
    "# Create Input-Output Pairs\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(sequences) - seq_length):\n",
    "    X.append(sequences[i:i + seq_length])\n",
    "    y.append(sequences[i + seq_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# Reshape for LSTM Input\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1]))\n",
    "\n",
    "# Model Definition\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 256, input_length=seq_length),\n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(256)),\n",
    "    Dropout(0.3),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Model Summary\n",
    "\n",
    "\n",
    "# Checkpointing\n",
    "\n",
    "\n",
    "# Load Best Weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a27254-b1a5-4f8d-9028-b566fafcc222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 256)          10240     \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100, 512)         1050624   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 512)          0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100, 512)         2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 512)              1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 40)                20520     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,658,344\n",
      "Trainable params: 2,657,320\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75f473-e0a1-4d62-aae4-b8f3779a7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 1.6762 - accuracy: 0.5036\n",
      "Epoch 1: loss improved from inf to 1.67616, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 283s 62ms/step - loss: 1.6762 - accuracy: 0.5036\n",
      "Epoch 2/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 1.3277 - accuracy: 0.6015\n",
      "Epoch 2: loss improved from 1.67616 to 1.32765, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 279s 62ms/step - loss: 1.3277 - accuracy: 0.6015\n",
      "Epoch 3/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 1.2285 - accuracy: 0.6283\n",
      "Epoch 3: loss improved from 1.32765 to 1.22855, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 283s 63ms/step - loss: 1.2285 - accuracy: 0.6283\n",
      "Epoch 4/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 1.1725 - accuracy: 0.6426\n",
      "Epoch 4: loss improved from 1.22855 to 1.17248, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 287s 64ms/step - loss: 1.1725 - accuracy: 0.6426\n",
      "Epoch 5/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 1.1316 - accuracy: 0.6536\n",
      "Epoch 5: loss improved from 1.17248 to 1.13155, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 285s 64ms/step - loss: 1.1316 - accuracy: 0.6536\n",
      "Epoch 6/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 1.1015 - accuracy: 0.6621\n",
      "Epoch 6: loss improved from 1.13155 to 1.10154, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 280s 63ms/step - loss: 1.1015 - accuracy: 0.6621\n",
      "Epoch 7/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 1.0765 - accuracy: 0.6686\n",
      "Epoch 7: loss improved from 1.10154 to 1.07651, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 282s 63ms/step - loss: 1.0765 - accuracy: 0.6686\n",
      "Epoch 8/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 1.0524 - accuracy: 0.6752\n",
      "Epoch 8: loss improved from 1.07651 to 1.05237, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 282s 63ms/step - loss: 1.0524 - accuracy: 0.6752\n",
      "Epoch 9/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 1.0344 - accuracy: 0.6796\n",
      "Epoch 9: loss improved from 1.05237 to 1.03438, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 285s 64ms/step - loss: 1.0344 - accuracy: 0.6796\n",
      "Epoch 10/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 1.0170 - accuracy: 0.6844\n",
      "Epoch 10: loss improved from 1.03438 to 1.01703, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 286s 64ms/step - loss: 1.0170 - accuracy: 0.6844\n",
      "Epoch 11/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 1.0010 - accuracy: 0.6889\n",
      "Epoch 11: loss improved from 1.01703 to 1.00098, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 281s 63ms/step - loss: 1.0010 - accuracy: 0.6889\n",
      "Epoch 12/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.9868 - accuracy: 0.6923\n",
      "Epoch 12: loss improved from 1.00098 to 0.98682, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 276s 62ms/step - loss: 0.9868 - accuracy: 0.6923\n",
      "Epoch 13/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.9751 - accuracy: 0.6963\n",
      "Epoch 13: loss improved from 0.98682 to 0.97508, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 277s 62ms/step - loss: 0.9751 - accuracy: 0.6963\n",
      "Epoch 14/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.9627 - accuracy: 0.6994\n",
      "Epoch 14: loss improved from 0.97508 to 0.96268, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 281s 63ms/step - loss: 0.9627 - accuracy: 0.6994\n",
      "Epoch 15/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.9502 - accuracy: 0.7028\n",
      "Epoch 15: loss improved from 0.96268 to 0.95022, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 284s 63ms/step - loss: 0.9502 - accuracy: 0.7028\n",
      "Epoch 16/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.9405 - accuracy: 0.7049\n",
      "Epoch 16: loss improved from 0.95022 to 0.94056, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 286s 64ms/step - loss: 0.9406 - accuracy: 0.7049\n",
      "Epoch 17/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.9302 - accuracy: 0.7086\n",
      "Epoch 17: loss improved from 0.94056 to 0.93021, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 276s 62ms/step - loss: 0.9302 - accuracy: 0.7086\n",
      "Epoch 18/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.9219 - accuracy: 0.7112\n",
      "Epoch 18: loss improved from 0.93021 to 0.92188, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 275s 61ms/step - loss: 0.9219 - accuracy: 0.7112\n",
      "Epoch 19/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.9127 - accuracy: 0.7134\n",
      "Epoch 19: loss improved from 0.92188 to 0.91272, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 277s 62ms/step - loss: 0.9127 - accuracy: 0.7134\n",
      "Epoch 20/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.9053 - accuracy: 0.7146\n",
      "Epoch 20: loss improved from 0.91272 to 0.90533, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 279s 62ms/step - loss: 0.9053 - accuracy: 0.7146\n",
      "Epoch 21/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8955 - accuracy: 0.7176\n",
      "Epoch 21: loss improved from 0.90533 to 0.89553, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 294s 66ms/step - loss: 0.8955 - accuracy: 0.7176\n",
      "Epoch 22/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8874 - accuracy: 0.7203\n",
      "Epoch 22: loss improved from 0.89553 to 0.88740, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 305s 68ms/step - loss: 0.8874 - accuracy: 0.7203\n",
      "Epoch 23/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8815 - accuracy: 0.7217\n",
      "Epoch 23: loss improved from 0.88740 to 0.88151, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 273s 61ms/step - loss: 0.8815 - accuracy: 0.7217\n",
      "Epoch 24/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8725 - accuracy: 0.7246\n",
      "Epoch 24: loss improved from 0.88151 to 0.87255, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 321s 72ms/step - loss: 0.8725 - accuracy: 0.7246\n",
      "Epoch 25/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.7247\n",
      "Epoch 25: loss improved from 0.87255 to 0.86896, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 292s 65ms/step - loss: 0.8690 - accuracy: 0.7247\n",
      "Epoch 26/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8617 - accuracy: 0.7259\n",
      "Epoch 26: loss improved from 0.86896 to 0.86170, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 338s 76ms/step - loss: 0.8617 - accuracy: 0.7259\n",
      "Epoch 27/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8551 - accuracy: 0.7292\n",
      "Epoch 27: loss improved from 0.86170 to 0.85506, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 376s 84ms/step - loss: 0.8551 - accuracy: 0.7292\n",
      "Epoch 28/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8508 - accuracy: 0.7302\n",
      "Epoch 28: loss improved from 0.85506 to 0.85078, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 286s 64ms/step - loss: 0.8508 - accuracy: 0.7302\n",
      "Epoch 29/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8470 - accuracy: 0.7310\n",
      "Epoch 29: loss improved from 0.85078 to 0.84698, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 272s 61ms/step - loss: 0.8470 - accuracy: 0.7310\n",
      "Epoch 30/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8438 - accuracy: 0.7316\n",
      "Epoch 30: loss improved from 0.84698 to 0.84376, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 283s 63ms/step - loss: 0.8438 - accuracy: 0.7316\n",
      "Epoch 31/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8367 - accuracy: 0.7349\n",
      "Epoch 31: loss improved from 0.84376 to 0.83670, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 274s 61ms/step - loss: 0.8367 - accuracy: 0.7349\n",
      "Epoch 32/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8316 - accuracy: 0.7357\n",
      "Epoch 32: loss improved from 0.83670 to 0.83167, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 280s 63ms/step - loss: 0.8317 - accuracy: 0.7357\n",
      "Epoch 33/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8278 - accuracy: 0.7366\n",
      "Epoch 33: loss improved from 0.83167 to 0.82779, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 277s 62ms/step - loss: 0.8278 - accuracy: 0.7366\n",
      "Epoch 34/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8237 - accuracy: 0.7374\n",
      "Epoch 34: loss improved from 0.82779 to 0.82371, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 278s 62ms/step - loss: 0.8237 - accuracy: 0.7374\n",
      "Epoch 35/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8191 - accuracy: 0.7388\n",
      "Epoch 35: loss improved from 0.82371 to 0.81912, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 301s 67ms/step - loss: 0.8191 - accuracy: 0.7388\n",
      "Epoch 36/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8196 - accuracy: 0.7380\n",
      "Epoch 36: loss did not improve from 0.81912\n",
      "4477/4477 [==============================] - 292s 65ms/step - loss: 0.8196 - accuracy: 0.7380\n",
      "Epoch 37/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8127 - accuracy: 0.7399\n",
      "Epoch 37: loss improved from 0.81912 to 0.81270, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 304s 68ms/step - loss: 0.8127 - accuracy: 0.7399\n",
      "Epoch 38/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.8108 - accuracy: 0.7410\n",
      "Epoch 38: loss improved from 0.81270 to 0.81078, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 294s 66ms/step - loss: 0.8108 - accuracy: 0.7410\n",
      "Epoch 39/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8090 - accuracy: 0.7418\n",
      "Epoch 39: loss improved from 0.81078 to 0.80902, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 306s 68ms/step - loss: 0.8090 - accuracy: 0.7418\n",
      "Epoch 40/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8068 - accuracy: 0.7424\n",
      "Epoch 40: loss improved from 0.80902 to 0.80681, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 307s 69ms/step - loss: 0.8068 - accuracy: 0.7424\n",
      "Epoch 41/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.8006 - accuracy: 0.7444\n",
      "Epoch 41: loss improved from 0.80681 to 0.80054, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 305s 68ms/step - loss: 0.8005 - accuracy: 0.7444\n",
      "Epoch 42/50\n",
      "4477/4477 [==============================] - ETA: 0s - loss: 0.7997 - accuracy: 0.7444\n",
      "Epoch 42: loss improved from 0.80054 to 0.79974, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 330s 74ms/step - loss: 0.7997 - accuracy: 0.7444\n",
      "Epoch 43/50\n",
      "4476/4477 [============================>.] - ETA: 0s - loss: 0.7969 - accuracy: 0.7452\n",
      "Epoch 43: loss improved from 0.79974 to 0.79690, saving model to weights-best.hdf5\n",
      "4477/4477 [==============================] - 334s 75ms/step - loss: 0.7969 - accuracy: 0.7452\n",
      "Epoch 44/50\n",
      "3039/4477 [===================>..........] - ETA: 1:45 - loss: 0.7869 - accuracy: 0.7471"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-best.hdf5\", monitor=\"loss\", save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a489371-24fe-44a5-821f-0588970bbd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "for _ in range(1000):  # Generate 1000 characters\n",
    "    pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "    pred_probs = model.predict(pred_input, verbose=0)\n",
    "    next_idx = np.argmax(pred_probs)\n",
    "    output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "    seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\"\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0698fb40-c3c9-4aab-b328-760df270b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  stress\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: onsultmstatements 4 american psychiatric association and substance use disorders and adhd in the pre\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the trained model\n",
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Define the knowledge base\n",
    "with open('mental_h.txt', 'r', encoding='utf-8') as file:\n",
    "    knowledge_base = file.read()\n",
    "\n",
    "# Extract knowledge base sections\n",
    "def find_relevant_info(user_input, knowledge_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([knowledge_text, user_input])\n",
    "    similarity = vectorizer.toarray().dot(vectorizer.toarray().T)[0, 1]\n",
    "    if similarity > 0.1:\n",
    "        # Extract sentences with relevance\n",
    "        return '\\n'.join([sentence for sentence in knowledge_text.splitlines() if user_input.lower() in sentence.lower()])\n",
    "    return \"I don't have specific information about that. Let's explore general advice.\"\n",
    "\n",
    "# Generate a creative response\n",
    "def generate_response(user_input, tokenizer, model, max_sequence_length, output_length=100):\n",
    "    input_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=max_sequence_length, padding='pre')\n",
    "\n",
    "    output = []\n",
    "    for _ in range(output_length):\n",
    "        pred_probs = model.predict(input_sequence, verbose=0)\n",
    "        next_idx = np.argmax(pred_probs)\n",
    "        output.append(tokenizer.index_word.get(next_idx, \"\"))\n",
    "\n",
    "        input_sequence = np.append(input_sequence[0][1:], next_idx).reshape(1, max_sequence_length)\n",
    "\n",
    "    return \"\".join(output)\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"You: \")\n",
    "relevant_info = find_relevant_info(user_input, knowledge_base)\n",
    "creative_response = generate_response(user_input, tokenizer, model, max_sequence_length=100, output_length=100)\n",
    "\n",
    "response = f\"Here is some information related to your query:\\n{relevant_info}\\n\\nChatbot: {creative_response}\"\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc7998b-e40f-4e89-a4b6-b13c19bce245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "e mental health professionals and support to seek treatment options and can help a person’s mental health is a basic and include problems and support to more than the stressors are also present and prevent mental health at work is a loss of person continuity of suicide and substance use disorders in adults with mental health conditions and psychosocial disasters and suicide and well-being.\n",
      "\n",
      "the development of mental health conditions in the brain that are several family, and individuals may feel an important to recommends person to mental illnesses and the professional will recommend that a person’s behavior and support workers with bipolar disorder (adhd) is a common mental health conditions are more likely to experience personal activity and antidepressant medications and an individual with a mental health professionals and support to a depressive episode and depression in the brain that they are more likely to develop better services and support to provide support to the internal for physical health care and treatment of mental health conditions and psychosocial support and support from the stressors are more likely to develop a mental health condition that become the brain common mental health at work and environmental services and complex medications that may be improved to mental health conditions and the mental health condition that are more likely to experience a person’s mental health at work is a basic and severe depression, anxiety, and suicide is a service part of the prevalence of mental health conditions. the mental health condition that are also present and that the presynaptic neuron that they may also be provided to treat mental health conditions and psychosocial risk to suicide and self-harm has been control of the mediterranean diet that are provided to seek help from the brain that promote the mental health condition to the person’s mental health is a setting to support the prevalence of mental health conditions can be a person’s mental health co.\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "temperature = 1.0  # Lower values make text more deterministic; higher values make it more diverse.\n",
    "\n",
    "for i in range(2000):  # Generate 1000 characters\n",
    "    if i<1500:\n",
    "        pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "        pred_probs = model.predict(pred_input, verbose=0)\n",
    "        next_idx = np.argmax(pred_probs)\n",
    "        output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "        seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "        \n",
    "    else:\n",
    "        if seed_idx == \".\":\n",
    "            break\n",
    "        else:\n",
    "            pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "            pred_probs = model.predict(pred_input, verbose=0)\n",
    "            next_idx = np.argmax(pred_probs)\n",
    "            output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "            # Update seed sequence\n",
    "            seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "            \n",
    "        \n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\"\".join(output)+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d30ed-4b77-46c1-890f-550c1c372995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
