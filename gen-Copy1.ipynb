{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f1fb7b-02ae-420b-8d7d-f0b5dd3299bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, BatchNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Load and Preprocess Data\n",
    "filename = \"mental_H.txt\"\n",
    "with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    raw_text = file.read().lower()\n",
    "import re\n",
    "\n",
    "# Remove unnecessary characters and normalize text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = text.strip().lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "raw_text = clean_text(raw_text)\n",
    "\n",
    "# Tokenization\n",
    "##\n",
    "tokenizer = Tokenizer(num_words=5000)  # Limit vocab size to 5000\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "##\n",
    "sequences = tokenizer.texts_to_sequences([raw_text])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "##\n",
    "seq_length = 150\n",
    "\n",
    "# Create Input-Output Pairs\n",
    "X = []\n",
    "y = []\n",
    "for i in range(0, len(sequences) - seq_length):\n",
    "    X.append(sequences[i:i + seq_length])\n",
    "    y.append(sequences[i + seq_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# Reshape for LSTM Input\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1]))\n",
    "\n",
    "# Model Definition\n",
    "##\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 256, input_length=seq_length),\n",
    "    Bidirectional(LSTM(256, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    Bidirectional(LSTM(256)),\n",
    "    Dropout(0.3),\n",
    "    Dense(vocab_size, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93a27254-b1a5-4f8d-9028-b566fafcc222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 150, 256)          1294592   \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 150, 512)         1050624   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 150, 512)          0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 150, 512)         2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 512)              1574912   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5057)              2594241   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,516,417\n",
      "Trainable params: 6,515,393\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e75f473-e0a1-4d62-aae4-b8f3779a7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 6.6721 - accuracy: 0.0630\n",
      "Epoch 1: loss improved from inf to 6.67208, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 58s 79ms/step - loss: 6.6721 - accuracy: 0.0630\n",
      "Epoch 2/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 6.2044 - accuracy: 0.1013\n",
      "Epoch 2: loss improved from 6.67208 to 6.20436, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 6.2044 - accuracy: 0.1013\n",
      "Epoch 3/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 5.9117 - accuracy: 0.1215\n",
      "Epoch 3: loss improved from 6.20436 to 5.91173, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 53s 79ms/step - loss: 5.9117 - accuracy: 0.1215\n",
      "Epoch 4/100\n",
      "674/675 [============================>.] - ETA: 0s - loss: 5.6580 - accuracy: 0.1382\n",
      "Epoch 4: loss improved from 5.91173 to 5.65807, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 5.6581 - accuracy: 0.1382\n",
      "Epoch 5/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 5.3866 - accuracy: 0.1549\n",
      "Epoch 5: loss improved from 5.65807 to 5.38665, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 5.3866 - accuracy: 0.1549\n",
      "Epoch 6/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 5.1051 - accuracy: 0.1698\n",
      "Epoch 6: loss improved from 5.38665 to 5.10505, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 53s 78ms/step - loss: 5.1051 - accuracy: 0.1698\n",
      "Epoch 7/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 4.8077 - accuracy: 0.1868\n",
      "Epoch 7: loss improved from 5.10505 to 4.80767, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 53s 78ms/step - loss: 4.8077 - accuracy: 0.1868\n",
      "Epoch 8/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 4.4980 - accuracy: 0.2070\n",
      "Epoch 8: loss improved from 4.80767 to 4.49799, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 4.4980 - accuracy: 0.2070\n",
      "Epoch 9/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 4.2379 - accuracy: 0.2250\n",
      "Epoch 9: loss improved from 4.49799 to 4.23794, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 79ms/step - loss: 4.2379 - accuracy: 0.2250\n",
      "Epoch 10/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 3.9037 - accuracy: 0.2542\n",
      "Epoch 10: loss improved from 4.23794 to 3.90370, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 3.9037 - accuracy: 0.2542\n",
      "Epoch 11/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 3.5960 - accuracy: 0.2883\n",
      "Epoch 11: loss improved from 3.90370 to 3.59599, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 3.5960 - accuracy: 0.2883\n",
      "Epoch 12/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 3.3130 - accuracy: 0.3230\n",
      "Epoch 12: loss improved from 3.59599 to 3.31295, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 3.3130 - accuracy: 0.3230\n",
      "Epoch 13/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 3.0460 - accuracy: 0.3630\n",
      "Epoch 13: loss improved from 3.31295 to 3.04601, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 3.0460 - accuracy: 0.3630\n",
      "Epoch 14/100\n",
      "674/675 [============================>.] - ETA: 0s - loss: 2.8188 - accuracy: 0.3983\n",
      "Epoch 14: loss improved from 3.04601 to 2.81902, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 2.8190 - accuracy: 0.3982\n",
      "Epoch 15/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 2.6033 - accuracy: 0.4333\n",
      "Epoch 15: loss improved from 2.81902 to 2.60326, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 53s 78ms/step - loss: 2.6033 - accuracy: 0.4333\n",
      "Epoch 16/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 2.4215 - accuracy: 0.4637\n",
      "Epoch 16: loss improved from 2.60326 to 2.42151, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 79ms/step - loss: 2.4215 - accuracy: 0.4637\n",
      "Epoch 17/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 2.2628 - accuracy: 0.4889\n",
      "Epoch 17: loss improved from 2.42151 to 2.26282, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 2.2628 - accuracy: 0.4889\n",
      "Epoch 18/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 2.1119 - accuracy: 0.5198\n",
      "Epoch 18: loss improved from 2.26282 to 2.11189, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 2.1119 - accuracy: 0.5198\n",
      "Epoch 19/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.9743 - accuracy: 0.5417\n",
      "Epoch 19: loss improved from 2.11189 to 1.97434, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 1.9743 - accuracy: 0.5417\n",
      "Epoch 20/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.8510 - accuracy: 0.5645\n",
      "Epoch 20: loss improved from 1.97434 to 1.85102, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 1.8510 - accuracy: 0.5645\n",
      "Epoch 21/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.7238 - accuracy: 0.5912\n",
      "Epoch 21: loss improved from 1.85102 to 1.72379, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 1.7238 - accuracy: 0.5912\n",
      "Epoch 22/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.6212 - accuracy: 0.6136\n",
      "Epoch 22: loss improved from 1.72379 to 1.62119, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 58s 85ms/step - loss: 1.6212 - accuracy: 0.6136\n",
      "Epoch 23/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.5234 - accuracy: 0.6337\n",
      "Epoch 23: loss improved from 1.62119 to 1.52342, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 58s 86ms/step - loss: 1.5234 - accuracy: 0.6337\n",
      "Epoch 24/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.4207 - accuracy: 0.6533\n",
      "Epoch 24: loss improved from 1.52342 to 1.42074, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 1.4207 - accuracy: 0.6533\n",
      "Epoch 25/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.3335 - accuracy: 0.6714\n",
      "Epoch 25: loss improved from 1.42074 to 1.33353, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 84ms/step - loss: 1.3335 - accuracy: 0.6714\n",
      "Epoch 26/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.2591 - accuracy: 0.6855\n",
      "Epoch 26: loss improved from 1.33353 to 1.25909, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 1.2591 - accuracy: 0.6855\n",
      "Epoch 27/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.1732 - accuracy: 0.7061\n",
      "Epoch 27: loss improved from 1.25909 to 1.17321, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 1.1732 - accuracy: 0.7061\n",
      "Epoch 28/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.1058 - accuracy: 0.7217\n",
      "Epoch 28: loss improved from 1.17321 to 1.10576, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 58s 85ms/step - loss: 1.1058 - accuracy: 0.7217\n",
      "Epoch 29/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.0417 - accuracy: 0.7388\n",
      "Epoch 29: loss improved from 1.10576 to 1.04169, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 1.0417 - accuracy: 0.7388\n",
      "Epoch 30/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.9802 - accuracy: 0.7487\n",
      "Epoch 30: loss improved from 1.04169 to 0.98020, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 84ms/step - loss: 0.9802 - accuracy: 0.7487\n",
      "Epoch 31/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.9212 - accuracy: 0.7630\n",
      "Epoch 31: loss improved from 0.98020 to 0.92120, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.9212 - accuracy: 0.7630\n",
      "Epoch 32/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.7743\n",
      "Epoch 32: loss improved from 0.92120 to 0.87070, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 0.8707 - accuracy: 0.7743\n",
      "Epoch 33/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.8211 - accuracy: 0.7848\n",
      "Epoch 33: loss improved from 0.87070 to 0.82111, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.8211 - accuracy: 0.7848\n",
      "Epoch 34/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.7747 - accuracy: 0.7985\n",
      "Epoch 34: loss improved from 0.82111 to 0.77474, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 58s 85ms/step - loss: 0.7747 - accuracy: 0.7985\n",
      "Epoch 35/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.7397 - accuracy: 0.8055\n",
      "Epoch 35: loss improved from 0.77474 to 0.73969, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.7397 - accuracy: 0.8055\n",
      "Epoch 36/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.8150\n",
      "Epoch 36: loss improved from 0.73969 to 0.69670, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.6967 - accuracy: 0.8150\n",
      "Epoch 37/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.6620 - accuracy: 0.8228\n",
      "Epoch 37: loss improved from 0.69670 to 0.66202, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.6620 - accuracy: 0.8228\n",
      "Epoch 38/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.8341\n",
      "Epoch 38: loss improved from 0.66202 to 0.61557, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.6156 - accuracy: 0.8341\n",
      "Epoch 39/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.5888 - accuracy: 0.8438\n",
      "Epoch 39: loss improved from 0.61557 to 0.58880, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.5888 - accuracy: 0.8438\n",
      "Epoch 40/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.8486\n",
      "Epoch 40: loss improved from 0.58880 to 0.56741, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 0.5674 - accuracy: 0.8486\n",
      "Epoch 41/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.8548\n",
      "Epoch 41: loss improved from 0.56741 to 0.53924, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 0.5392 - accuracy: 0.8548\n",
      "Epoch 42/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.8610\n",
      "Epoch 42: loss improved from 0.53924 to 0.51124, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.5112 - accuracy: 0.8610\n",
      "Epoch 43/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8664\n",
      "Epoch 43: loss improved from 0.51124 to 0.49142, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.4914 - accuracy: 0.8664\n",
      "Epoch 44/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.8727\n",
      "Epoch 44: loss improved from 0.49142 to 0.46708, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.4671 - accuracy: 0.8727\n",
      "Epoch 45/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.8791\n",
      "Epoch 45: loss improved from 0.46708 to 0.44204, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.4420 - accuracy: 0.8791\n",
      "Epoch 46/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.4356 - accuracy: 0.8802\n",
      "Epoch 46: loss improved from 0.44204 to 0.43559, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 0.4356 - accuracy: 0.8802\n",
      "Epoch 47/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.4075 - accuracy: 0.8899\n",
      "Epoch 47: loss improved from 0.43559 to 0.40753, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.4075 - accuracy: 0.8899\n",
      "Epoch 48/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3950 - accuracy: 0.8922\n",
      "Epoch 48: loss improved from 0.40753 to 0.39497, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 82ms/step - loss: 0.3950 - accuracy: 0.8922\n",
      "Epoch 49/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.8967\n",
      "Epoch 49: loss improved from 0.39497 to 0.37758, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.3776 - accuracy: 0.8967\n",
      "Epoch 50/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.8998\n",
      "Epoch 50: loss improved from 0.37758 to 0.36376, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 82ms/step - loss: 0.3638 - accuracy: 0.8998\n",
      "Epoch 51/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.9023\n",
      "Epoch 51: loss improved from 0.36376 to 0.35736, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 82ms/step - loss: 0.3574 - accuracy: 0.9023\n",
      "Epoch 52/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.9049\n",
      "Epoch 52: loss improved from 0.35736 to 0.34661, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.3466 - accuracy: 0.9049\n",
      "Epoch 53/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.9087\n",
      "Epoch 53: loss improved from 0.34661 to 0.32846, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.3285 - accuracy: 0.9087\n",
      "Epoch 54/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.9084\n",
      "Epoch 54: loss improved from 0.32846 to 0.32835, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.3283 - accuracy: 0.9084\n",
      "Epoch 55/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.3194 - accuracy: 0.9100\n",
      "Epoch 55: loss improved from 0.32835 to 0.31943, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.3194 - accuracy: 0.9100\n",
      "Epoch 56/100\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.3081 - accuracy: 0.9146\n",
      "Epoch 56: loss improved from 0.31943 to 0.30807, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 0.3081 - accuracy: 0.9146\n",
      "Epoch 57/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2949 - accuracy: 0.9184\n",
      "Epoch 57: loss improved from 0.30807 to 0.29486, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 79ms/step - loss: 0.2949 - accuracy: 0.9184\n",
      "Epoch 58/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2846 - accuracy: 0.9207\n",
      "Epoch 58: loss improved from 0.29486 to 0.28461, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.2846 - accuracy: 0.9207\n",
      "Epoch 59/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.9198\n",
      "Epoch 59: loss did not improve from 0.28461\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 0.2855 - accuracy: 0.9198\n",
      "Epoch 60/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.9243\n",
      "Epoch 60: loss improved from 0.28461 to 0.27088, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 53s 79ms/step - loss: 0.2709 - accuracy: 0.9243\n",
      "Epoch 61/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.9213\n",
      "Epoch 61: loss did not improve from 0.27088\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 0.2763 - accuracy: 0.9213\n",
      "Epoch 62/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.9255\n",
      "Epoch 62: loss improved from 0.27088 to 0.26194, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.2619 - accuracy: 0.9255\n",
      "Epoch 63/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.9315\n",
      "Epoch 63: loss improved from 0.26194 to 0.24442, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 82ms/step - loss: 0.2444 - accuracy: 0.9315\n",
      "Epoch 64/100\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9301\n",
      "Epoch 64: loss did not improve from 0.24442\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 0.2477 - accuracy: 0.9301\n",
      "Epoch 65/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 0.9280\n",
      "Epoch 65: loss did not improve from 0.24442\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.2497 - accuracy: 0.9280\n",
      "Epoch 66/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9321\n",
      "Epoch 66: loss improved from 0.24442 to 0.23836, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.2384 - accuracy: 0.9321\n",
      "Epoch 67/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.9321\n",
      "Epoch 67: loss improved from 0.23836 to 0.23689, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 82ms/step - loss: 0.2369 - accuracy: 0.9321\n",
      "Epoch 68/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.9356\n",
      "Epoch 68: loss improved from 0.23689 to 0.22694, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.2269 - accuracy: 0.9356\n",
      "Epoch 69/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9351\n",
      "Epoch 69: loss did not improve from 0.22694\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.2276 - accuracy: 0.9351\n",
      "Epoch 70/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.9327\n",
      "Epoch 70: loss did not improve from 0.22694\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.2317 - accuracy: 0.9327\n",
      "Epoch 71/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9341\n",
      "Epoch 71: loss did not improve from 0.22694\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 0.2276 - accuracy: 0.9341\n",
      "Epoch 72/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9386\n",
      "Epoch 72: loss improved from 0.22694 to 0.21758, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 58s 85ms/step - loss: 0.2176 - accuracy: 0.9386\n",
      "Epoch 73/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9394\n",
      "Epoch 73: loss improved from 0.21758 to 0.21076, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.2108 - accuracy: 0.9394\n",
      "Epoch 74/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9411\n",
      "Epoch 74: loss improved from 0.21076 to 0.20598, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.2060 - accuracy: 0.9411\n",
      "Epoch 75/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.9384\n",
      "Epoch 75: loss did not improve from 0.20598\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.2144 - accuracy: 0.9384\n",
      "Epoch 76/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9379\n",
      "Epoch 76: loss did not improve from 0.20598\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.2148 - accuracy: 0.9379\n",
      "Epoch 77/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2031 - accuracy: 0.9421\n",
      "Epoch 77: loss improved from 0.20598 to 0.20308, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.2031 - accuracy: 0.9421\n",
      "Epoch 78/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2020 - accuracy: 0.9420\n",
      "Epoch 78: loss improved from 0.20308 to 0.20201, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.2020 - accuracy: 0.9420\n",
      "Epoch 79/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9415\n",
      "Epoch 79: loss improved from 0.20201 to 0.20071, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.2007 - accuracy: 0.9415\n",
      "Epoch 80/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9433\n",
      "Epoch 80: loss improved from 0.20071 to 0.19712, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 0.1971 - accuracy: 0.9433\n",
      "Epoch 81/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.9427\n",
      "Epoch 81: loss improved from 0.19712 to 0.19534, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 54s 81ms/step - loss: 0.1953 - accuracy: 0.9427\n",
      "Epoch 82/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9447\n",
      "Epoch 82: loss improved from 0.19534 to 0.19239, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 82ms/step - loss: 0.1924 - accuracy: 0.9447\n",
      "Epoch 83/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.9435\n",
      "Epoch 83: loss improved from 0.19239 to 0.18960, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.1896 - accuracy: 0.9435\n",
      "Epoch 84/100\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1862 - accuracy: 0.9451\n",
      "Epoch 84: loss improved from 0.18960 to 0.18620, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.1862 - accuracy: 0.9450\n",
      "Epoch 85/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9448\n",
      "Epoch 85: loss did not improve from 0.18620\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.1912 - accuracy: 0.9448\n",
      "Epoch 86/100\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9460\n",
      "Epoch 86: loss improved from 0.18620 to 0.18594, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.1859 - accuracy: 0.9460\n",
      "Epoch 87/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.9500\n",
      "Epoch 87: loss improved from 0.18594 to 0.17252, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.1725 - accuracy: 0.9500\n",
      "Epoch 88/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9513\n",
      "Epoch 88: loss did not improve from 0.17252\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.1726 - accuracy: 0.9513\n",
      "Epoch 89/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9484\n",
      "Epoch 89: loss did not improve from 0.17252\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.1779 - accuracy: 0.9484\n",
      "Epoch 90/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9477\n",
      "Epoch 90: loss did not improve from 0.17252\n",
      "675/675 [==============================] - 57s 84ms/step - loss: 0.1781 - accuracy: 0.9477\n",
      "Epoch 91/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.9487\n",
      "Epoch 91: loss did not improve from 0.17252\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.1736 - accuracy: 0.9487\n",
      "Epoch 92/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9483\n",
      "Epoch 92: loss did not improve from 0.17252\n",
      "675/675 [==============================] - 54s 80ms/step - loss: 0.1739 - accuracy: 0.9483\n",
      "Epoch 93/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9473\n",
      "Epoch 93: loss did not improve from 0.17252\n",
      "675/675 [==============================] - 55s 82ms/step - loss: 0.1767 - accuracy: 0.9473\n",
      "Epoch 94/100\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 0.9507\n",
      "Epoch 94: loss improved from 0.17252 to 0.17036, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.1704 - accuracy: 0.9507\n",
      "Epoch 95/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.9508\n",
      "Epoch 95: loss improved from 0.17036 to 0.16816, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 56s 82ms/step - loss: 0.1682 - accuracy: 0.9508\n",
      "Epoch 96/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9495\n",
      "Epoch 96: loss did not improve from 0.16816\n",
      "675/675 [==============================] - 56s 83ms/step - loss: 0.1710 - accuracy: 0.9495\n",
      "Epoch 97/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.9503\n",
      "Epoch 97: loss did not improve from 0.16816\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.1689 - accuracy: 0.9503\n",
      "Epoch 98/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.9508\n",
      "Epoch 98: loss improved from 0.16816 to 0.16466, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.1647 - accuracy: 0.9508\n",
      "Epoch 99/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.9545\n",
      "Epoch 99: loss improved from 0.16466 to 0.15642, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 55s 81ms/step - loss: 0.1564 - accuracy: 0.9545\n",
      "Epoch 100/100\n",
      "675/675 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9545\n",
      "Epoch 100: loss improved from 0.15642 to 0.15543, saving model to weights-best1.hdf5\n",
      "675/675 [==============================] - 57s 85ms/step - loss: 0.1554 - accuracy: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1688a3c4c40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-best1.hdf5\", monitor=\"loss\", save_best_only=True, verbose=1)\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "# Train the Model\n",
    "model.fit(X, y, epochs=100, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a489371-24fe-44a5-821f-0588970bbd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "tends to run in families strongly suggests that the disease has a genetic component children who have adhd usually have at least one close relative who also has the disorder24 one group of researchers found that a child whose identical twin has adhd is 11 to 18 times more likely to develop the disorder than a nontwin sibling investigations of particular genes involved in adhd have focused on a dopamine receptor gene drd on chromosome 11 and the dopamine transporter gene dat1 on chromosome 544 ongoing studies continue to examine these genes and others as factors in adhd most likely a combination of several genes and environmental factors determines whether a person has adhd imaging studies have shown differences in the brains of boys with adhd compared with boys who do not have adhd researchers found that certain parts of the brain are on average smaller in boys with adhd8 other studies found that the total brain volume is smaller in girls who have adhd than in control subjects these results match similar findings about the brains of boys with adhd9 scientists have speculated that the changes in the particular brain regions may be involved in the inability to inhibit thoughts which is a symptom of adhd treating adhd a variety of medications and behavioral interventions are used to treat adhd the most widely used medications are methylphenidate ritalin damphetamine and other amphetamines these drugs are stimulants that affect the level of the neurotransmitter dopamine at the synapse40 nine out of 10 children improve while taking one of these drugs19 when used as prescribed by qualified physicians these drugs are considered quite safe side effects associated with moderate doses are decreased appetite and insomnia these side effects generally occur early in treatment and often decrease with time some studies have shown that the stimulants used to treat adhd decrease growth rate but ultimate height is not affected interventions used to treat adhd include several forms of psychotherapy such as cognitivebehavioral therapy social skills training support groups and parent and educator skills training a combination of medication and psychotherapy is more effective than either treatment alone in improving social skills parentchild relations reading achievement and aggressive symptoms24 treating adhd with a combination of medication and psychotherapy is more effective than either treatment alone in improving social skills parentchild relations reading achievement and aggressive symptoms in addition to the wellestablished treatments described above some parents and therapists have tried a variety of nutritional interventions to treat adhd a few studies have found that some children benefit from such treatments nevertheless no wellestablished nutritional interventions have consistently been shown to be effective for treating adhd24 coping with adhd as the symptoms indicate adhd interferes with a persons daily life treatment is available to help individuals and relieve the symptoms but some simple strategies including those listed below can also help asking the teacher or boss to repeat instructions rather than guessing what they were breaking large assignments or job tasks into small simple tasks set a deadline for each task and give a reward as each one is completed making a list of what needs to be done each day plan the best order for doing each task then make a schedule for doing them use a calendar or daily planner to keep on track working in a quiet area do one thing at a time take short breaks writing things that need to be remembered in a notebook with dividers carry the book at all times posting notes as reminders of things to do storing similar things together creating a routine get ready for school or work at the same time in the same way every day exercising eating a balanced diet and getting enough sleep schizophrenia schizophrenia affects approximately 1 percent of the population or 22 million us adults men and women are equally affected25 32 the illness usually emerges in young people in their teens or twenties although children over the age of five can develop schizophrenia it is rare before adolescence21 in children the disease usually develops gradually and is often preceded by developmental delays in motor or speech development childhoodonset schizophrenia tends to be harder to treat and has a less favorable prognosis than does the adultonset form the symptoms of schizophrenia there are many myths and misconceptions about schizophrenia schizophrenia is not a multiple or split personality nor are individuals who have this illness constantly incoherent or psychotic although the media often portray individuals with schizophrenia as violent in reality very few affected people are dangerous to others32 in fact individuals with schizophrenia are more likely to be victims of violence than violent themselves schizophrenia has severe symptoms a diagnosis of schizophrenia requires that at least two of the symptoms below be present during a significant portion of a onemonth period delusions false beliefs such as conspiracies mind control or persecution hallucinations usually voices criticizing or commenting on the persons behavior disorganized speech incomprehensible or difficult to understand grossly disorganized or catatonic behavior and negative symptoms such as flat emotions lack of facial expressions and inattention to basic selfcare needs such as bathing and eating5 however the presence of either one of the first two symptoms is sufficient to diagnose schizophrenia if the delusions are especially bizarre or if the hallucinations consist of one or more voices that keep a running commentary on the persons behavior or thoughts5 the dsmiv specifies additional criteria for a diagnosis of schizophrenia social or occupational dysfunction persistence of the disturbance for at least six months exclusion of a mood disorder exclusion of a substanceabuse or medical condition that causes similar symptoms and consideration of a possible pervasive developmental disorder44 the course of schizophrenia varies considerably from one individual to the next most people who have schizophrenia experience at least one and usually more relapses after their first psychotic episode32 relapses are periods of more intense symptoms of illness hallucinations and delusions during remissions the negative symptoms related to emotion or personal\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights-best1.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "for _ in range(1000):  # Generate 1000 characters\n",
    "    pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "    pred_probs = model.predict(pred_input, verbose=0)\n",
    "    next_idx = np.argmax(pred_probs)\n",
    "    output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "    seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\" \".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698fb40-c3c9-4aab-b328-760df270b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the trained model\n",
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Define the knowledge base\n",
    "with open('mental_h.txt', 'r', encoding='utf-8') as file:\n",
    "    knowledge_base = file.read()\n",
    "\n",
    "# Extract knowledge base sections\n",
    "def find_relevant_info(user_input, knowledge_text):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([knowledge_text, user_input])\n",
    "    similarity = vectorizer.toarray().dot(vectorizer.toarray().T)[0, 1]\n",
    "    if similarity > 0.1:\n",
    "        # Extract sentences with relevance\n",
    "        return '\\n'.join([sentence for sentence in knowledge_text.splitlines() if user_input.lower() in sentence.lower()])\n",
    "    return \"I don't have specific information about that. Let's explore general advice.\"\n",
    "\n",
    "# Generate a creative response\n",
    "def generate_response(user_input, tokenizer, model, max_sequence_length, output_length=100):\n",
    "    input_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=max_sequence_length, padding='pre')\n",
    "\n",
    "    output = []\n",
    "    for _ in range(output_length):\n",
    "        pred_probs = model.predict(input_sequence, verbose=0)\n",
    "        next_idx = np.argmax(pred_probs)\n",
    "        output.append(tokenizer.index_word.get(next_idx, \"\"))\n",
    "\n",
    "        input_sequence = np.append(input_sequence[0][1:], next_idx).reshape(1, max_sequence_length)\n",
    "\n",
    "    return \"\".join(output)\n",
    "\n",
    "# Example usage\n",
    "user_input = input(\"You: \")\n",
    "relevant_info = find_relevant_info(user_input, knowledge_base)\n",
    "creative_response = generate_response(user_input, tokenizer, model, max_sequence_length=100, output_length=100)\n",
    "\n",
    "response = f\"Here is some information related to your query:\\n{relevant_info}\\n\\nChatbot: {creative_response}\"\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7998b-e40f-4e89-a4b6-b13c19bce245",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights-best.hdf5\")\n",
    "\n",
    "# Generate Text\n",
    "seed_idx = np.random.randint(0, len(X) - 1)\n",
    "seed_sequence = X[seed_idx]\n",
    "\n",
    "output = []\n",
    "temperature = 1.0  # Lower values make text more deterministic; higher values make it more diverse.\n",
    "\n",
    "for i in range(2000):  # Generate 1000 characters\n",
    "    if i<1500:\n",
    "        pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "        pred_probs = model.predict(pred_input, verbose=0)\n",
    "        next_idx = np.argmax(pred_probs)\n",
    "        output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "    # Update seed sequence\n",
    "        seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "        \n",
    "    else:\n",
    "        if seed_idx == \".\":\n",
    "            break\n",
    "        else:\n",
    "            pred_input = np.reshape(seed_sequence, (1, len(seed_sequence)))\n",
    "            pred_probs = model.predict(pred_input, verbose=0)\n",
    "            next_idx = np.argmax(pred_probs)\n",
    "            output.append(tokenizer.index_word[next_idx])\n",
    "\n",
    "            # Update seed sequence\n",
    "            seed_sequence = np.append(seed_sequence[1:], next_idx)\n",
    "            \n",
    "        \n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(\"\".join(output)+\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0d30ed-4b77-46c1-890f-550c1c372995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
